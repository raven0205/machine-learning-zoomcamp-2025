{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bWwyEhelyJSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# !pip install torchvision\n",
        "import torchvision\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#!pip install torchmetrics\n",
        "import torchmetrics"
      ],
      "metadata": {
        "id": "_j6ZX0tSyA9b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the dataset for CNN"
      ],
      "metadata": {
        "id": "5RUaSHDWyYef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-7ZILoWO7O9V"
      },
      "outputs": [],
      "source": [
        "#!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
        "#!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "-h-cUwEOyWFh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "For this homework we will use Convolutional Neural Network (CNN). We'll use PyTorch.\n",
        "\n",
        "You need to develop the model with following structure:\n",
        "\n",
        "1. The shape for input should be (3, 200, 200) (channels first format in PyTorch)\n",
        "2. Next, create a convolutional layer (nn.Conv2d):\n",
        "- Use 32 filters (output channels)\n",
        "- Kernel size should be (3, 3) (that's the size of the filter)\n",
        "- Use 'relu' as activation\n",
        "3. Reduce the size of the feature map with max pooling (nn.MaxPool2d)\n",
        "- Set the pooling size to (2, 2)\n",
        "4. Turn the multi-dimensional result into vectors using flatten or view\n",
        "5. Next, add a nn.Linear layer with 64 neurons and 'relu' activation\n",
        "6. Finally, create the nn.Linear layer with 1 neuron - this will be the output\n",
        "7. The output layer should have an activation - use the appropriate activation for the binary classification case\n",
        "8. As optimizer use torch.optim.SGD with the following parameters:\n",
        "```\n",
        "torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
        "```"
      ],
      "metadata": {
        "id": "Ayqt_vxB4iSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "   def __init__(self):\n",
        "\n",
        "       \"\"\"\n",
        "       CNN model for binary classification.\n",
        "       Parameters:\n",
        "           * in_channels: Number of channels in the input image (for grayscale images, 1)\n",
        "           * num_classes: Number of classes to predict. In our problem, 10 (i.e digits from  0 to 9).\n",
        "\n",
        "       Architecture:\n",
        "       - Conv2d layer with 32 filters, kernel size (3,3), ReLU\n",
        "       - MaxPool 2d layer size (2,2)\n",
        "       - Flatten\n",
        "       - Linear -> 64, ReLU\n",
        "       - Linear -> 1, Sigmoid\n",
        "       \"\"\"\n",
        "       super(CNN, self).__init__()\n",
        "\n",
        "       # 1. the shape of the input should be (3,200,200)\n",
        "       # 1st convolutional layer\n",
        "       self.conv1 = nn.Conv2d(\n",
        "           in_channels=3,\n",
        "           out_channels=32,\n",
        "           kernel_size=3,\n",
        "           padding=1        # same padding -> output stays 200x200\n",
        "           )\n",
        "       # 2. Max pooling layer\n",
        "       self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "       # After Conv + Pool:\n",
        "       # Input: (3,200,200)\n",
        "       # Conv1 : (32,200,200)\n",
        "       # Pool: (32,100,100)\n",
        "\n",
        "       # Flatten or view Next\n",
        "       flattened_size = 32*100*100\n",
        "\n",
        "       # 3. First fully connected layer (64 neurons)\n",
        "       self.fc1 = nn.Linear(flattened_size, 64)\n",
        "\n",
        "       # 4. Final output linear layer: 1 neuron\n",
        "       self.fc2 = nn.Linear(64,1)\n",
        "\n",
        "       # Sigmoid activation for probability output\n",
        "       self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "   def forward(self, x):\n",
        "       \"\"\"\n",
        "       Define the forward pass of the neural network.\n",
        "\n",
        "       Parameters:\n",
        "           x: Input tensor.\n",
        "\n",
        "       Returns:\n",
        "           torch.Tensor\n",
        "               The output tensor after passing through the network.\n",
        "       \"\"\"\n",
        "       x = F.relu(self.conv1(x))  # Apply first convolution and ReLU activation\n",
        "       x = self.pool(x)           # Apply max pooling\n",
        "       x = x.reshape(x.shape[0], -1)  # Flatten the tensor\n",
        "       x = self.fc1(x)            # Apply first fully connected layer\n",
        "       x = F.relu(x)           # ReLU\n",
        "       x = self.fc2(x)                    # Dense Output Layer\n",
        "       x = self.sigmoid(x)                # Sigmoid activation for binary classification\n",
        "       return x\n",
        "\n",
        "# Optimizer\n",
        "model = CNN()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)"
      ],
      "metadata": {
        "id": "VCyiMYA1zQuf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqmwhG1u0Yc4",
        "outputId": "69c50a8c-82d6-4c14-9555-8cddedadf0b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=320000, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create some random test data (batch size = 4)\n",
        "x_test = torch.randn(4,3,200,200)\n",
        "y_test_binary = torch.randint(0,2,(4,1)).float() # for BCE/MSE\n",
        "y_test_class = torch.randint(0,10,(4,1))  # for CrossEntropy\n",
        "y_test_cos = torch.randn(4,1)  # for CosineEmbedding\n",
        "\n",
        "# Loss functions to test\n",
        "criterions_dict = {\n",
        "    \"MSELoss\": nn.MSELoss(),\n",
        "    \"BCEWithLogitsLoss\": nn.BCEWithLogitsLoss(),\n",
        "    \"CrossEntropyLoss\": nn.CrossEntropyLoss(),\n",
        "    \"CosineEmbeddingLoss\": nn.CosineEmbeddingLoss()\n",
        "}\n",
        "\n",
        "print(\"\\n=== Testing loss functions ===\")\n",
        "\n",
        "for name, criterion in criterions_dict.items():\n",
        "    print(f\"\\n{name}\")\n",
        "    try:\n",
        "        # Forward pass\n",
        "        outputs = model(x_test)\n",
        "\n",
        "        if name == \"CrossEntropyLoss\":\n",
        "            # CE needs logits of shape (batch, num_classes)\n",
        "            # model outputs (batch, 1) → will ERROR (this is expected)\n",
        "            loss = criterion(outputs, y_test_class)\n",
        "\n",
        "        elif name == \"CosineEmbeddingLoss\":\n",
        "            # Cosine requires same shape + target of +1 / -1\n",
        "            loss = criterion(outputs, torch.randn_like(outputs), y_test_cos)\n",
        "\n",
        "        else:\n",
        "            # MSELoss, BCEWithLogitsLoss\n",
        "            loss = criterion(outputs, y_test_binary)\n",
        "\n",
        "        print(\"Loss:\", loss.item())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYJVvEog5hwE",
        "outputId": "50160625-83e6-4957-8027-ca7bd1c8e2bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Testing loss functions ===\n",
            "\n",
            "MSELoss\n",
            "Loss: 0.2633136212825775\n",
            "\n",
            "BCEWithLogitsLoss\n",
            "Loss: 0.7338293194770813\n",
            "\n",
            "CrossEntropyLoss\n",
            "Error: Expected floating point type for target with class probabilities, got Long\n",
            "\n",
            "CosineEmbeddingLoss\n",
            "Error: 0D or 1D target tensor expected, multi-target not supported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2 What's the total number of parameters of the model?\n",
        "\n",
        "# Option 1: Using torchsummary (install with: pip install torchsummary)\n",
        "from torchsummary import summary\n",
        "sm = summary(model, input_size=(3, 200, 200))\n",
        "print(sm)\n",
        "\n",
        "print(\"--------------### Alternative ###-------------\")\n",
        "# Option 2: Manual counting\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gusOZFZRLRT5",
        "outputId": "ccafb4ed-8cde-4021-b088-b3e2e17b50ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 200, 200]             896\n",
            "         MaxPool2d-2         [-1, 32, 100, 100]               0\n",
            "            Linear-3                   [-1, 64]      20,480,064\n",
            "            Linear-4                    [-1, 1]              65\n",
            "           Sigmoid-5                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 20,481,025\n",
            "Trainable params: 20,481,025\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.46\n",
            "Forward/backward pass size (MB): 12.21\n",
            "Params size (MB): 78.13\n",
            "Estimated Total Size (MB): 90.79\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "--------------### Alternative ###-------------\n",
            "Total parameters: 20481025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generators and training\n",
        "\n",
        "# To transform both train and tests sets\n",
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((200,200)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )  # ImageNet normalization\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# -----------------------\n",
        "# Train DataLoader\n",
        "# -----------------------\n",
        "# Locate Images dir\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root='data/train',\n",
        "    transform = train_transforms\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers = 2\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Val DataLoader\n",
        "# -----------------------\n",
        "validation_dataset = datasets.ImageFolder(\n",
        "    root='data/test',\n",
        "    transform = train_transforms\n",
        ")\n",
        "\n",
        "validation_loader = DataLoader(\n",
        "    validation_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers = 2\n",
        ")\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = correct_train / total_train\n",
        "    history['loss'].append(epoch_loss)\n",
        "    history['acc'].append(epoch_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "    history['val_loss'].append(val_epoch_loss)\n",
        "    history['val_acc'].append(val_epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpvglph1Lwz1",
        "outputId": "b9be71fc-db13-4e62-cd2b-08abf961c5cb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6843, Acc: 0.4875, Val Loss: 0.6668, Val Acc: 0.4876\n",
            "Epoch 2/10, Loss: 0.6579, Acc: 0.4875, Val Loss: 0.6555, Val Acc: 0.4876\n",
            "Epoch 3/10, Loss: 0.6465, Acc: 0.4875, Val Loss: 0.6555, Val Acc: 0.4876\n",
            "Epoch 4/10, Loss: 0.6397, Acc: 0.4875, Val Loss: 0.6560, Val Acc: 0.4876\n",
            "Epoch 5/10, Loss: 0.6312, Acc: 0.4875, Val Loss: 0.6594, Val Acc: 0.4876\n",
            "Epoch 6/10, Loss: 0.6282, Acc: 0.4875, Val Loss: 0.6683, Val Acc: 0.4876\n",
            "Epoch 7/10, Loss: 0.6209, Acc: 0.4875, Val Loss: 0.6593, Val Acc: 0.4876\n",
            "Epoch 8/10, Loss: 0.6165, Acc: 0.4875, Val Loss: 0.6593, Val Acc: 0.4876\n",
            "Epoch 9/10, Loss: 0.6114, Acc: 0.4875, Val Loss: 0.6605, Val Acc: 0.4876\n",
            "Epoch 10/10, Loss: 0.6067, Acc: 0.4875, Val Loss: 0.6669, Val Acc: 0.4876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Data Augmentation\n",
        "\n",
        "# part2. To add transformations for both train and test separately\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(50),                    # rotate up to ±50 degrees\n",
        "    transforms.RandomResizedCrop(\n",
        "        200,\n",
        "        scale=(0.9, 1.0),\n",
        "        ratio=(0.9, 1.1)\n",
        "    ),                                               # random crop + resize to 200x200\n",
        "    transforms.RandomHorizontalFlip(),               # flip left-right\n",
        "    transforms.ToTensor(),                           # convert image → tensor (0–1)\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],      # normalize (ImageNet mean/std)\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# -----------------------\n",
        "# Train DataLoader\n",
        "# -----------------------\n",
        "# Locate Images dir\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root='data/train',\n",
        "    transform = train_transforms\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers = 2\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Val DataLoader\n",
        "# -----------------------\n",
        "validation_dataset = datasets.ImageFolder(\n",
        "    root='data/test',\n",
        "    transform = val_transforms\n",
        ")\n",
        "\n",
        "validation_loader = DataLoader(\n",
        "    validation_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers = 2\n",
        ")\n",
        "\n",
        "# running epochs\n",
        "\n",
        "num_epochs = 10\n",
        "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = correct_train / total_train\n",
        "    history['loss'].append(epoch_loss)\n",
        "    history['acc'].append(epoch_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "    history['val_loss'].append(val_epoch_loss)\n",
        "    history['val_acc'].append(val_epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_W7qt5PUs2a",
        "outputId": "d226e992-fc4f-479f-c42c-39d4d454d282"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6336, Acc: 0.4900, Val Loss: 0.6469, Val Acc: 0.4975\n",
            "Epoch 2/10, Loss: 0.6371, Acc: 0.4913, Val Loss: 0.6468, Val Acc: 0.4975\n",
            "Epoch 3/10, Loss: 0.6343, Acc: 0.4900, Val Loss: 0.6484, Val Acc: 0.4975\n",
            "Epoch 4/10, Loss: 0.6264, Acc: 0.4925, Val Loss: 0.6512, Val Acc: 0.4975\n",
            "Epoch 5/10, Loss: 0.6353, Acc: 0.4900, Val Loss: 0.6486, Val Acc: 0.5025\n",
            "Epoch 6/10, Loss: 0.6382, Acc: 0.4938, Val Loss: 0.6464, Val Acc: 0.4975\n",
            "Epoch 7/10, Loss: 0.6289, Acc: 0.4913, Val Loss: 0.6499, Val Acc: 0.5025\n",
            "Epoch 8/10, Loss: 0.6301, Acc: 0.4938, Val Loss: 0.6481, Val Acc: 0.4975\n",
            "Epoch 9/10, Loss: 0.6295, Acc: 0.4913, Val Loss: 0.6514, Val Acc: 0.4975\n",
            "Epoch 10/10, Loss: 0.6320, Acc: 0.4925, Val Loss: 0.6469, Val Acc: 0.4975\n"
          ]
        }
      ]
    }
  ]
}