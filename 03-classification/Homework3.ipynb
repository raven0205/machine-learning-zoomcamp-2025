{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfb930b8-6e99-4cb6-b80e-70df5b9a3af0",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of the options exactly.\n",
    "> That's fine.\n",
    "> Select the option that's closest to your solution.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this homework, we will use the lead scoring dataset Bank Marketing dataset. Download it from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv).\n",
    "\n",
    "Or you can do it with `wget`:\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
    "```\n",
    "\n",
    "In this dataset our desired target for classification task will be `converted` variable - has the client signed up to the platform or not.\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For categorical features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 \n",
    "\n",
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `industry`?\n",
    "\n",
    "- `NA`\n",
    "- `technology`\n",
    "- `healthcare`\n",
    "- `retail`\n",
    "\n",
    "### Question 2\n",
    "\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset.\n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "- `interaction_count` and `lead_score`\n",
    "- `number_of_courses_viewed` and `lead_score`\n",
    "- `number_of_courses_viewed` and `interaction_count`\n",
    "- `annual_income` and `interaction_count`\n",
    "\n",
    "Only consider the pairs above when answering this question.\n",
    "\n",
    "### Split the data\n",
    "\n",
    "- Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "- Make sure that the target value `converted` is not in your dataframe.\n",
    "\n",
    "### Question 3\n",
    "\n",
    "- Calculate the mutual information score between `converted` and other categorical variables in the dataset. Use the training set only.\n",
    "- Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the biggest mutual information score?\n",
    "\n",
    "- `industry`\n",
    "- `location`\n",
    "- `lead_source`\n",
    "- `employment_status`\n",
    "\n",
    "### Question 4\n",
    "\n",
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "  - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "  - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "- 0.64\n",
    "- 0.74\n",
    "- 0.84\n",
    "- 0.94\n",
    "\n",
    "### Question 5\n",
    "\n",
    "- Let's find the least useful feature using the _feature elimination_ technique.\n",
    "- Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "- `'industry'`\n",
    "- `'employment_status'`\n",
    "- `'lead_score'`\n",
    "\n",
    "> **Note**: The difference doesn't have to be positive.\n",
    "\n",
    "### Question 6\n",
    "\n",
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "- Train models using all the features as in Q4.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these `C` leads to the best accuracy on the validation set?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "- 100\n",
    "\n",
    "> **Note**: If there are multiple options, select the smallest `C`.\n",
    "\n",
    "## Submit the results\n",
    "\n",
    "- Submit your results here: https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw03\n",
    "- If your answer doesn't match options exactly, select the closest one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7942353b-2ac5-49b5-b10e-82bbffd070a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "## import data\n",
    "#!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a99d65-5fc4-4f7e-a979-170726836398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source                  object\n",
      "industry                     object\n",
      "number_of_courses_viewed      int64\n",
      "annual_income               float64\n",
      "employment_status            object\n",
      "location                     object\n",
      "interaction_count             int64\n",
      "lead_score                  float64\n",
      "converted                     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Loading data\n",
    "df = pd.read_csv(\"course_lead_scoring.csv\")\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed4c02b-bbc1-4fd9-8c6c-fd8cd41de1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
      "0      paid_ads         NaN                         1        79450.0   \n",
      "1  social_media      retail                         1        46992.0   \n",
      "2        events  healthcare                         5        78796.0   \n",
      "3      paid_ads      retail                         2        83843.0   \n",
      "4      referral   education                         3        85012.0   \n",
      "\n",
      "  employment_status       location  interaction_count  lead_score  converted  \n",
      "0        unemployed  south_america                  4        0.94          1  \n",
      "1          employed  south_america                  1        0.80          0  \n",
      "2        unemployed      australia                  3        0.69          1  \n",
      "3               NaN      australia                  1        0.87          0  \n",
      "4     self_employed         europe                  3        0.62          1  \n",
      "##########\n",
      "lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n",
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(\"##########\")\n",
    "print(df.isna().sum()) # number of null values\n",
    "\n",
    "\n",
    "for feature in df.columns:\n",
    "    # impute numerical features\n",
    "    if df[feature].dtype == 'int64':\n",
    "        df[feature] = df[feature].fillna(0)\n",
    "    elif df[feature].dtype == 'float64':\n",
    "        df[feature] = df[feature].fillna(0.0)\n",
    "    # impute categorical features\n",
    "    elif df[feature].dtype == 'object':\n",
    "        df[feature] = df[feature].fillna('NA')\n",
    "\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc39fce-c53d-4d1f-8521-e21db25c3f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    retail\n",
       "Name: industry, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### question 1 find the mode of the column `industry`\n",
    "df.industry.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae6d829-4c2d-4690-818c-6d0b5c1e503e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d866419b-2ca2-4889-818d-c51783f56d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>-0.023565</td>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.435914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.053131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>-0.023565</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.374573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converted</th>\n",
       "      <td>0.435914</td>\n",
       "      <td>0.053131</td>\n",
       "      <td>0.374573</td>\n",
       "      <td>0.193673</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          number_of_courses_viewed  annual_income  \\\n",
       "number_of_courses_viewed                  1.000000       0.009770   \n",
       "annual_income                             0.009770       1.000000   \n",
       "interaction_count                        -0.023565       0.027036   \n",
       "lead_score                               -0.004879       0.015610   \n",
       "converted                                 0.435914       0.053131   \n",
       "\n",
       "                          interaction_count  lead_score  converted  \n",
       "number_of_courses_viewed          -0.023565   -0.004879   0.435914  \n",
       "annual_income                      0.027036    0.015610   0.053131  \n",
       "interaction_count                  1.000000    0.009888   0.374573  \n",
       "lead_score                         0.009888    1.000000   0.193673  \n",
       "converted                          0.374573    0.193673   1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### question 2 find the correlation of numerical features \n",
    "df_num = df.select_dtypes(include=['int64', 'float64'])\n",
    "df_num.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f52f2efd-0467-42e8-bf53-60cf45ee7058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['interaction_count'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9701b48d-32fa-4b3f-8458-b5f7a7b2f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009888182496913131\n",
      "-0.004878998354681276\n",
      "-0.023565222882888037\n",
      "0.02703647240481443\n"
     ]
    }
   ],
   "source": [
    "### question 2 print out correlation score\n",
    "corr_mat = df_num.corr()\n",
    "print(corr_mat.loc[('interaction_count', 'lead_score')])\n",
    "print(corr_mat.loc[('number_of_courses_viewed', 'lead_score')])\n",
    "print(corr_mat.loc[('number_of_courses_viewed', 'interaction_count')])\n",
    "print(corr_mat.loc[('annual_income', 'interaction_count')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f793c975-6da2-4b0c-a304-c0c91bae8990",
   "metadata": {},
   "outputs": [],
   "source": [
    "### question 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# train test split into feature matrix (X) and target (y)\n",
    "target = 'converted'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# First Split: Train (60%) vs. Temporary (40%) followed by Second Split: Test (50%) and Val (50%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X,y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp,y_temp, test_size=0.4, random_state=42, stratify=y_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48b64b0c-8f1a-4c80-afdf-8ecb53a6e255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c0d72dc-2dda-4ebf-8648-0db106ba1710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source_events                 0.03\n",
      "lead_source_organic_search         0.02\n",
      "industry_NA                        0.02\n",
      "lead_source_NA                     0.01\n",
      "lead_source_paid_ads               0.01\n",
      "lead_source_referral               0.01\n",
      "industry_education                 0.01\n",
      "industry_healthcare                0.01\n",
      "industry_finance                   0.01\n",
      "industry_manufacturing             0.01\n",
      "industry_other                     0.01\n",
      "location_asia                      0.01\n",
      "employment_status_student          0.01\n",
      "location_africa                    0.01\n",
      "lead_source_social_media           0.00\n",
      "employment_status_NA               0.00\n",
      "employment_status_employed         0.00\n",
      "industry_technology                0.00\n",
      "industry_retail                    0.00\n",
      "employment_status_unemployed       0.00\n",
      "employment_status_self_employed    0.00\n",
      "location_NA                        0.00\n",
      "location_australia                 0.00\n",
      "location_europe                    0.00\n",
      "location_middle_east               0.00\n",
      "location_north_america             0.00\n",
      "location_south_america             0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### question 3 extract categorical columns\n",
    "cat_columns = ['lead_source','industry','employment_status','location']\n",
    "X_train_categorical = X_train[cat_columns]\n",
    "\n",
    "# impute missing values\n",
    "X_train_categorical = X_train_categorical.fillna('unknown')\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# use one hot encoding to convert categorical columns \n",
    "X_train_encoded = pd.get_dummies(X_train_categorical, dtype=float)\n",
    "            \n",
    "### calculate mutual information scores\n",
    "mi_scores = mutual_info_classif(X_train_encoded, y_train, random_state=42)\n",
    "mi_series = pd.Series(mi_scores,index = X_train_encoded.columns) # added column names as index\n",
    "\n",
    "print(mi_series.round(2).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dffc805d-e243-4c99-a2d7-26eed76e41d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    }
   ],
   "source": [
    "### question 4 fit the logistic regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "\n",
    "# extract the categorical variables\n",
    "X_val_categorical = X_val[cat_columns]\n",
    "# impute missing values\n",
    "X_val_categorical = X_val_categorical.fillna('NA')\n",
    "# one hot encoding on the val data\n",
    "X_val_encoded = pd.get_dummies(X_val_categorical, dtype=float)\n",
    "# align the columns and reindex\n",
    "X_val_aligned = X_val_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "# fit the model and get the accuracy score\n",
    "model.fit(X_train_encoded,y_train)\n",
    "model_accuracy = model.score(X_val_aligned,y_val)\n",
    "print(round(model_accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fd0408a-aa6e-44b0-b5f8-07fec723dfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lead_source_NA': np.int64(10), 'lead_source_events': np.int64(4), 'lead_source_organic_search': np.int64(3), 'lead_source_paid_ads': np.int64(1), 'lead_source_referral': np.int64(1), 'lead_source_social_media': np.int64(14), 'industry_NA': np.int64(2), 'industry_education': np.int64(1), 'industry_finance': np.int64(6), 'industry_healthcare': np.int64(9), 'industry_manufacturing': np.int64(24), 'industry_other': np.int64(22), 'industry_retail': np.int64(13), 'industry_technology': np.int64(15), 'employment_status_NA': np.int64(21), 'employment_status_employed': np.int64(16), 'employment_status_self_employed': np.int64(11), 'employment_status_student': np.int64(17), 'employment_status_unemployed': np.int64(1), 'location_NA': np.int64(8), 'location_africa': np.int64(20), 'location_asia': np.int64(23), 'location_australia': np.int64(5), 'location_europe': np.int64(12), 'location_middle_east': np.int64(18), 'location_north_america': np.int64(19), 'location_south_america': np.int64(7)}\n",
      "Index(['lead_source_paid_ads', 'lead_source_referral', 'industry_education',\n",
      "       'employment_status_unemployed'],\n",
      "      dtype='object')\n",
      "Validation accuracy: 0.6410256410256411\n"
     ]
    }
   ],
   "source": [
    "### question 5 \n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=4, step=1, verbose=0)\n",
    "rfe.fit(X_train_encoded,y_train)\n",
    "\n",
    "print(dict(zip(X_train_encoded.columns, rfe.ranking_))) # print their importance rank\n",
    "print(X_train_encoded.columns[rfe.support_])  # print the remaining features\n",
    "\n",
    "acc = rfe.score(X_val_aligned,y_val)\n",
    "print(\"Validation accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa075b2a-d5b7-4579-9c83-ea26789dca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Accuracy Difference\n",
      "0           industry             0.016752\n",
      "1  employment_status             0.003932\n",
      "2        lead_source             0.021026\n"
     ]
    }
   ],
   "source": [
    "### question 5\n",
    "orig_acc = 0.62\n",
    "# compute the accuracy by dropping one feature at a time\n",
    "accuracy = {}\n",
    "\n",
    "cols = ['industry', 'employment_status','lead_source']\n",
    "\n",
    "for feature in cols:\n",
    "    # take out the feature relevant columns, i.e industry_x, industry_y \n",
    "    cols_to_drop = [c for c in X_train_encoded.columns if c.startswith(feature)]\n",
    "    X_train_drop = X_train_encoded.drop(columns=cols_to_drop)\n",
    "    X_val_drop = X_val_encoded.drop(columns=cols_to_drop)\n",
    "\n",
    "    # Retrain model without that feature\n",
    "    model = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "    model.fit(X_train_drop, y_train)\n",
    "\n",
    "    # compute the new accuracy score\n",
    "    acc = model.score(X_val_drop, y_val)\n",
    "    diff = acc - orig_acc\n",
    "\n",
    "    # attach the difference for that feature\n",
    "    accuracy[feature] = diff\n",
    "\n",
    "accu = pd.DataFrame(accuracy.items(), columns=['Feature', 'Accuracy Difference'])\n",
    "print(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d8da940-f523-4e43-a9cb-db85c8aa8c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.632\n"
     ]
    }
   ],
   "source": [
    "### question 6\n",
    "# Logistic Regression with L1 regularization and cross-validation\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and fit the LassoCV model on the training set\n",
    "logreg_cv = LogisticRegressionCV(\n",
    "    penalty='l1', \n",
    "    solver='saga',  # 'saga' supports L1 regularization\n",
    "    cv=5,           \n",
    "    Cs=[0.01, 0.1, 1, 10, 100],\n",
    "    scoring='accuracy',\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "logreg_cv.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = logreg_cv.predict(X_val_encoded)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "522f2df2-b229-462c-9d2c-6cf3c04e3066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C selected by CV: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Best C selected by CV:\", logreg_cv.C_[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
