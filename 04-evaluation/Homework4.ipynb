{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92b5794-cc75-4f3f-a9dc-5b64b582c12f",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "> Note: sometimes your answer doesn't match one of \n",
    "> the options exactly. That's fine. \n",
    "> Select the option that's closest to your solution.\n",
    "\n",
    "\n",
    "In this homework, we will use the lead scoring dataset Bank Marketing dataset. Download it from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv).\n",
    "\n",
    "\n",
    "In this dataset our desired target for classification task will be `converted` variable - has the client signed up to the platform or not. \n",
    "\n",
    "### Data preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For caterogiral features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 \n",
    "\n",
    "\n",
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` function for that with `random_state=1`\n",
    "\n",
    "\n",
    "### Question 1: ROC AUC feature importance\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables. \n",
    "\n",
    "Let's do that\n",
    "\n",
    "* For each numerical variable, use it as score (aka prediction) and compute the AUC with the `y` variable as ground truth.\n",
    "* Use the training dataset for that\n",
    "\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. `-df_train['balance']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target variable. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- `lead_score`\n",
    "- `number_of_courses_viewed`\n",
    "- `interaction_count`\n",
    "- `annual_income`\n",
    "\n",
    "### Question 2: Training the model\n",
    "\n",
    "Apply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n",
    "\n",
    "```python\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "```\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "- 0.32\n",
    "- 0.52\n",
    "- 0.72\n",
    "- 0.92\n",
    "\n",
    "\n",
    "### Question 3: Precision and Recall\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "* For each threshold, compute precision and recall\n",
    "* Plot them\n",
    "\n",
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "* 0.145\n",
    "* 0.345\n",
    "* 0.545\n",
    "* 0.745\n",
    "\n",
    "\n",
    "### Question 4: F1 score\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n",
    "\n",
    "Where $P$ is precision and $R$ is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "- 0.14\n",
    "- 0.34\n",
    "- 0.54\n",
    "- 0.74\n",
    "\n",
    "\n",
    "### Question 5: 5-Fold CV\n",
    "\n",
    "\n",
    "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "```\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "```\n",
    "\n",
    "* Iterate over different folds of `df_full_train`\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "* Use AUC to evaluate the model on validation\n",
    "\n",
    "How large is standard deviation of the scores across different folds?\n",
    "\n",
    "- 0.0001\n",
    "- 0.006\n",
    "- 0.06\n",
    "- 0.36\n",
    "\n",
    "\n",
    "### Question 6: Hyperparameter Tuning\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter `C`\n",
    "\n",
    "* Iterate over the following `C` values: `[0.000001, 0.001, 1]`\n",
    "* Initialize `KFold` with the same parameters as previously\n",
    "* Use these parameters for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "Which `C` leads to the best mean score?\n",
    "\n",
    "- 0.000001\n",
    "- 0.001\n",
    "- 1\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest `C`.\n",
    "\n",
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw04\n",
    "* If your answer doesn't match options exactly, select the closest one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5822457c-361a-489b-acf0-137be6cee123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-19 01:04:28--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2025-10-19 01:04:29 (26.3 MB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "## import data\n",
    "#!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b132039-9faf-40ea-a138-e00b60854679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## checking the dtypes ##\n",
      "lead_source                  object\n",
      "industry                     object\n",
      "number_of_courses_viewed      int64\n",
      "annual_income               float64\n",
      "employment_status            object\n",
      "location                     object\n",
      "interaction_count             int64\n",
      "lead_score                  float64\n",
      "converted                     int64\n",
      "dtype: object\n",
      "## checking the number of total NAs ##\n",
      "lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Loading data\n",
    "df = pd.read_csv(\"course_lead_scoring.csv\")\n",
    "\n",
    "print(\"## checking the dtypes ##\")\n",
    "print(df.dtypes)\n",
    "print(\"## checking the number of total NAs ##\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db76dccc-4ffd-45e1-b82c-f3e69c457edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# impute the missing values\n",
    "for feature in df.columns:\n",
    "    # impute numerical features\n",
    "    if df[feature].dtype == 'int64':\n",
    "        df[feature] = df[feature].fillna(0)\n",
    "    elif df[feature].dtype == 'float64':\n",
    "        df[feature] = df[feature].fillna(0.0)\n",
    "    # impute categorical features\n",
    "    elif df[feature].dtype == 'object':\n",
    "        df[feature] = df[feature].fillna('NA')\n",
    "        \n",
    "### checking for missing values\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4826621e-35b8-40e5-ba79-07e0b0c1e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "# random state\n",
    "n = 1\n",
    "\n",
    "# train test split into feature matrix (X) and target (y)\n",
    "target = 'converted'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# First Split: Train (60%) vs. Temporary (40%) followed by Second Split: Test (50%) and Val (50%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X,y, test_size=0.4, random_state=n, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp,y_temp, test_size=0.4, random_state=n, stratify=y_temp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
