{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbae99fb-c168-441f-8e10-dd967d53558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f77b40-bfe6-403a-ab9d-6bb1a03f266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-30 13:26:33--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 874188 (854K) [text/plain]\n",
      "Saving to: ‘car_fuel_efficiency.csv’\n",
      "\n",
      "car_fuel_efficiency 100%[===================>] 853.70K  --.-KB/s    in 0.006s  \n",
      "\n",
      "2025-10-30 13:26:34 (147 MB/s) - ‘car_fuel_efficiency.csv’ saved [874188/874188]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b1a3084-00f3-4455-a668-6b36a0da4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"car_fuel_efficiency.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f46d1f0-b53d-45f4-b6d1-ee77844a9c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9704 entries, 0 to 9703\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   engine_displacement  9704 non-null   int64  \n",
      " 1   num_cylinders        9222 non-null   float64\n",
      " 2   horsepower           8996 non-null   float64\n",
      " 3   vehicle_weight       9704 non-null   float64\n",
      " 4   acceleration         8774 non-null   float64\n",
      " 5   model_year           9704 non-null   int64  \n",
      " 6   origin               9704 non-null   object \n",
      " 7   fuel_type            9704 non-null   object \n",
      " 8   drivetrain           9704 non-null   object \n",
      " 9   num_doors            9202 non-null   float64\n",
      " 10  fuel_efficiency_mpg  9704 non-null   float64\n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 834.1+ KB\n",
      "None\n",
      "(9704, 11)\n",
      "       engine_displacement  num_cylinders   horsepower  vehicle_weight  \\\n",
      "count          9704.000000    9222.000000  8996.000000     9704.000000   \n",
      "mean            199.708368       3.962481   149.657292     3001.280993   \n",
      "std              49.455319       1.999323    29.879555      497.894860   \n",
      "min              10.000000       0.000000    37.000000      952.681761   \n",
      "25%             170.000000       3.000000   130.000000     2666.248985   \n",
      "50%             200.000000       4.000000   149.000000     2993.226296   \n",
      "75%             230.000000       5.000000   170.000000     3334.957039   \n",
      "max             380.000000      13.000000   271.000000     4739.077089   \n",
      "\n",
      "       acceleration   model_year    num_doors  fuel_efficiency_mpg  \n",
      "count   8774.000000  9704.000000  9202.000000          9704.000000  \n",
      "mean      15.021928  2011.484027    -0.006412            14.985243  \n",
      "std        2.510339     6.659808     1.048162             2.556468  \n",
      "min        6.000000  2000.000000    -4.000000             6.200971  \n",
      "25%       13.300000  2006.000000    -1.000000            13.267459  \n",
      "50%       15.000000  2012.000000     0.000000            15.006037  \n",
      "75%       16.700000  2017.000000     1.000000            16.707965  \n",
      "max       24.300000  2023.000000     4.000000            25.967222  \n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.shape)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f450faf-faa6-43d9-aad6-79d5871fd458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin  fuel_type  drivetrain       \n",
      "Asia    Gasoline   All-wheel drive      877\n",
      "Europe  Gasoline   All-wheel drive      825\n",
      "Asia    Diesel     Front-wheel drive    822\n",
      "Europe  Diesel     All-wheel drive      821\n",
      "                   Front-wheel drive    811\n",
      "USA     Gasoline   Front-wheel drive    805\n",
      "                   All-wheel drive      805\n",
      "        Diesel     Front-wheel drive    804\n",
      "Europe  Gasoline   Front-wheel drive    797\n",
      "Asia    Gasoline   Front-wheel drive    789\n",
      "USA     Diesel     All-wheel drive      789\n",
      "Asia    Diesel     All-wheel drive      759\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.select_dtypes(include=\"object\").value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3896ee7-f02d-49d8-8d8d-78a0b8268573",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data quality checks \n",
    "def check_outliers_zscore(series, threshold=3):\n",
    "    # Calculate Z-scores\n",
    "    z_scores = np.abs((series - series.mean()) / series.std())\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = series[z_scores > threshold]\n",
    "    \n",
    "    return {\n",
    "        'count': len(outliers),\n",
    "        'percentage': len(outliers) / len(series) * 100\n",
    "    }\n",
    "\n",
    "def validate_dataframe_comprehensive(df):\n",
    "    \"\"\"\n",
    "    Performs a comprehensive data quality check on the input DataFrame.\n",
    "    \"\"\"\n",
    "    # 1. Initial Format Check \n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        return False, \"Invalid DataFrame format. Expected a pandas DataFrame.\"\n",
    "    dtype_map = {\n",
    "        \"engine_displacement\": \"Int64\",\n",
    "        \"num_cylinders\": \"float64\",\n",
    "        \"horsepower\": \"float64\",\n",
    "        \"vehicle_weight\": \"float64\",\n",
    "        \"acceleration\": \"float64\",\n",
    "        \"model_year\": \"Int64\",\n",
    "        \"origin\": \"object\",\n",
    "        \"fuel_type\": \"object\",\n",
    "        \"drivetrain\": \"object\",\n",
    "        \"num_doors\": \"float64\",\n",
    "        \"fuel_efficiency_mpg\":\"float64\",\n",
    "    }        \n",
    "    # Check for missing/extra columns\n",
    "    if set(df.columns) != set(dtype_map.keys()):\n",
    "        print(f\"Column mismatch: Missing: {set(dtype_map.keys()) - set(df.columns)}\")\n",
    "        print(f\"Column mismatch: Extra: {set(df.columns) - set(dtype_map.keys())}\")\n",
    "        return False, \"Schema structure is incorrect.\"\n",
    "        \n",
    "    # check the data structure of the attributes\n",
    "    for col, expected_dtype in dtype_map.items():\n",
    "        if str(df[col].dtype) != expected_dtype.lower():\n",
    "            return False, f\"Invalid data type for {col}. Expected: {expected_dtype}.\"\n",
    "\n",
    "    # check for any null values and duplicate values\n",
    "    for col in dtype_map:\n",
    "        null_counts = df[col].isna().sum()\n",
    "        \n",
    "        if null_counts > 0:\n",
    "            print(f\"{col} has {null_counts} null values.\")\n",
    "    dup_counts = df.duplicated().sum()\n",
    "    print(f\"DataFrame df has {dup_counts} duplicate rows.\")\n",
    "    \n",
    "    # how to check for numerical outliers\n",
    "    for col in df.select_dtypes(include='number'):\n",
    "        report = check_outliers_zscore(df[col])\n",
    "        if report['count'] > 0:\n",
    "            print(f\"Outliers for {col}: {report['count']} ({report['percentage']:.2f}%)\")\n",
    "        else:\n",
    "            continue\n",
    "    return True, \"DataFrame is valid.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94c5a8cf-d2d1-4c45-ba48-967683a16ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cylinders has 482 null values.\n",
      "horsepower has 708 null values.\n",
      "acceleration has 930 null values.\n",
      "num_doors has 502 null values.\n",
      "DataFrame df has 0 duplicate rows.\n",
      "Outliers for engine_displacement: 39 (0.40%)\n",
      "Outliers for num_cylinders: 81 (0.83%)\n",
      "Outliers for horsepower: 19 (0.20%)\n",
      "Outliers for vehicle_weight: 28 (0.29%)\n",
      "Outliers for acceleration: 25 (0.26%)\n",
      "Outliers for num_doors: 5 (0.05%)\n",
      "Outliers for fuel_efficiency_mpg: 27 (0.28%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 'DataFrame is valid.')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Preparing the dataset\n",
    "validate_dataframe_comprehensive(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8a12407-3a71-4b1d-93f2-e36a08cec007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine_displacement    False\n",
      "num_cylinders          False\n",
      "horsepower             False\n",
      "vehicle_weight         False\n",
      "acceleration           False\n",
      "model_year             False\n",
      "origin                 False\n",
      "fuel_type              False\n",
      "drivetrain             False\n",
      "num_doors              False\n",
      "fuel_efficiency_mpg    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# fill missing values with zeros\n",
    "df1 = df.fillna(0)\n",
    "print(df1.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a76ee107-0aec-4a3a-bbaa-4abf016c5f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle_weight\n"
     ]
    }
   ],
   "source": [
    "### Question 1\n",
    "# Do train/validation/test split with 60%/20%/20% distribution. \n",
    "# Use the `train_test_split` function and set the `random_state` parameter to 1.\n",
    "# Use `DictVectorizer(sparse=True)` to turn the dataframes into matrices.\n",
    "\n",
    "df_train, df_temp = train_test_split(df1, \n",
    "                              random_state=1, \n",
    "                              test_size=0.4)\n",
    "df_val, df_test = train_test_split(df_temp, \n",
    "                                   random_state=1,\n",
    "                                   test_size=0.5)\n",
    "target = \"fuel_efficiency_mpg\"\n",
    "train_y = df_train[target]\n",
    "df_train_X = df_train.drop(columns=[target])\n",
    "test_y = df_test[target]\n",
    "df_test_X = df_test.drop(columns=[target])\n",
    "val_y = df_val[target]\n",
    "df_val_X = df_val.drop(columns=[target])\n",
    "\n",
    "# vectorize into matrix\n",
    "v = DictVectorizer(sparse=True)\n",
    "train_X_matrix = v.fit_transform(df_train_X.to_dict(orient='records'))\n",
    "val_X_matrix = v.transform(df_val_X.to_dict(orient='records'))\n",
    "test_X_matrix = v.transform(df_test_X.to_dict(orient='records'))\n",
    "\n",
    "# train a decision tree regressor to predict the `fuel_efficiency_mpg` variable\n",
    "DT = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "DT.fit(train_X_matrix, train_y)\n",
    "\n",
    "# print feature importance\n",
    "importances = DT.feature_importances_\n",
    "\n",
    "# Get the index of the most important feature\n",
    "idx = np.argmax([importances])\n",
    "\n",
    "# Get the feature name with the highest feature importance\n",
    "feature_names = v.feature_names_\n",
    "print(feature_names[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296273ea-01f7-4378-ae5a-d6dfb6d6da5c",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the `fuel_efficiency_mpg` variable. \n",
    "\n",
    "* Train a model with `max_depth=1`.\n",
    "\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "\n",
    "* `'vehicle_weight'`\n",
    "* `'model_year'`\n",
    "* `'origin'`\n",
    "* `'fuel_type'`\n",
    "\n",
    "\n",
    "## Question 2\n",
    "\n",
    "Train a random forest regressor with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1` (optional - to make training faster)\n",
    "\n",
    "\n",
    "What's the RMSE of this model on the validation data?\n",
    "\n",
    "* 0.045\n",
    "* 0.45\n",
    "* 4.5\n",
    "* 45.0\n",
    "\n",
    "\n",
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10.\n",
    "* Set `random_state` to `1`.\n",
    "* Evaluate the model on the validation dataset.\n",
    "\n",
    "\n",
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "Consider 3 decimal places for calculating the answer.\n",
    "\n",
    "- 10\n",
    "- 25\n",
    "- 80\n",
    "- 200\n",
    "\n",
    "If it doesn't stop improving, use the latest iteration number in\n",
    "your answer.\n",
    "\n",
    "\n",
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values,\n",
    "  * try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "  * calculate the mean RMSE \n",
    "* Fix the random seed: `random_state=1`\n",
    "\n",
    "\n",
    "What's the best `max_depth`, using the mean RMSE?\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25\n",
    "\n",
    "\n",
    "# Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorithm, it finds the best split. \n",
    "When doing it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the important features for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the\n",
    "[`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_)\n",
    "field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parameters:\n",
    "  * `n_estimators=10`,\n",
    "  * `max_depth=20`,\n",
    "  * `random_state=1`,\n",
    "  * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model\n",
    "\n",
    "\n",
    "What's the most important feature (among these 4)? \n",
    "\n",
    "* `vehicle_weight`\n",
    "*\t`horsepower`\n",
    "* `acceleration`\n",
    "* `engine_displacement`\t\n",
    "\n",
    "\n",
    "## Question 6\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter:\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```\n",
    "\n",
    "Now change `eta` from `0.3` to `0.1`.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* Both give equal value\n",
    "\n",
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw06\n",
    "* If your answer doesn't match options exactly, select the closest one. If the answer is exactly in between two options, select the higher value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa1090-6023-48b1-8cff-d79f13ced2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
