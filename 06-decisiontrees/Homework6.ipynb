{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbae99fb-c168-441f-8e10-dd967d53558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f77b40-bfe6-403a-ab9d-6bb1a03f266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-01 12:14:28--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 874188 (854K) [text/plain]\n",
      "Saving to: ‘car_fuel_efficiency.csv.1’\n",
      "\n",
      "car_fuel_efficiency 100%[===================>] 853.70K  --.-KB/s    in 0.006s  \n",
      "\n",
      "2025-11-01 12:14:29 (147 MB/s) - ‘car_fuel_efficiency.csv.1’ saved [874188/874188]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b1a3084-00f3-4455-a668-6b36a0da4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"car_fuel_efficiency.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f46d1f0-b53d-45f4-b6d1-ee77844a9c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9704 entries, 0 to 9703\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   engine_displacement  9704 non-null   int64  \n",
      " 1   num_cylinders        9222 non-null   float64\n",
      " 2   horsepower           8996 non-null   float64\n",
      " 3   vehicle_weight       9704 non-null   float64\n",
      " 4   acceleration         8774 non-null   float64\n",
      " 5   model_year           9704 non-null   int64  \n",
      " 6   origin               9704 non-null   object \n",
      " 7   fuel_type            9704 non-null   object \n",
      " 8   drivetrain           9704 non-null   object \n",
      " 9   num_doors            9202 non-null   float64\n",
      " 10  fuel_efficiency_mpg  9704 non-null   float64\n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 834.1+ KB\n",
      "None\n",
      "(9704, 11)\n",
      "       engine_displacement  num_cylinders   horsepower  vehicle_weight  \\\n",
      "count          9704.000000    9222.000000  8996.000000     9704.000000   \n",
      "mean            199.708368       3.962481   149.657292     3001.280993   \n",
      "std              49.455319       1.999323    29.879555      497.894860   \n",
      "min              10.000000       0.000000    37.000000      952.681761   \n",
      "25%             170.000000       3.000000   130.000000     2666.248985   \n",
      "50%             200.000000       4.000000   149.000000     2993.226296   \n",
      "75%             230.000000       5.000000   170.000000     3334.957039   \n",
      "max             380.000000      13.000000   271.000000     4739.077089   \n",
      "\n",
      "       acceleration   model_year    num_doors  fuel_efficiency_mpg  \n",
      "count   8774.000000  9704.000000  9202.000000          9704.000000  \n",
      "mean      15.021928  2011.484027    -0.006412            14.985243  \n",
      "std        2.510339     6.659808     1.048162             2.556468  \n",
      "min        6.000000  2000.000000    -4.000000             6.200971  \n",
      "25%       13.300000  2006.000000    -1.000000            13.267459  \n",
      "50%       15.000000  2012.000000     0.000000            15.006037  \n",
      "75%       16.700000  2017.000000     1.000000            16.707965  \n",
      "max       24.300000  2023.000000     4.000000            25.967222  \n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.shape)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f450faf-faa6-43d9-aad6-79d5871fd458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin  fuel_type  drivetrain       \n",
      "Asia    Gasoline   All-wheel drive      877\n",
      "Europe  Gasoline   All-wheel drive      825\n",
      "Asia    Diesel     Front-wheel drive    822\n",
      "Europe  Diesel     All-wheel drive      821\n",
      "                   Front-wheel drive    811\n",
      "USA     Gasoline   Front-wheel drive    805\n",
      "                   All-wheel drive      805\n",
      "        Diesel     Front-wheel drive    804\n",
      "Europe  Gasoline   Front-wheel drive    797\n",
      "Asia    Gasoline   Front-wheel drive    789\n",
      "USA     Diesel     All-wheel drive      789\n",
      "Asia    Diesel     All-wheel drive      759\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.select_dtypes(include=\"object\").value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3896ee7-f02d-49d8-8d8d-78a0b8268573",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data quality checks \n",
    "def check_outliers_zscore(series, threshold=3):\n",
    "    # Calculate Z-scores\n",
    "    z_scores = np.abs((series - series.mean()) / series.std())\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = series[z_scores > threshold]\n",
    "    \n",
    "    return {\n",
    "        'count': len(outliers),\n",
    "        'percentage': len(outliers) / len(series) * 100\n",
    "    }\n",
    "\n",
    "def validate_dataframe_comprehensive(df):\n",
    "    \"\"\"\n",
    "    Performs a comprehensive data quality check on the input DataFrame.\n",
    "    \"\"\"\n",
    "    # 1. Initial Format Check \n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        return False, \"Invalid DataFrame format. Expected a pandas DataFrame.\"\n",
    "    dtype_map = {\n",
    "        \"engine_displacement\": \"Int64\",\n",
    "        \"num_cylinders\": \"float64\",\n",
    "        \"horsepower\": \"float64\",\n",
    "        \"vehicle_weight\": \"float64\",\n",
    "        \"acceleration\": \"float64\",\n",
    "        \"model_year\": \"Int64\",\n",
    "        \"origin\": \"object\",\n",
    "        \"fuel_type\": \"object\",\n",
    "        \"drivetrain\": \"object\",\n",
    "        \"num_doors\": \"float64\",\n",
    "        \"fuel_efficiency_mpg\":\"float64\",\n",
    "    }        \n",
    "    # Check for missing/extra columns\n",
    "    if set(df.columns) != set(dtype_map.keys()):\n",
    "        print(f\"Column mismatch: Missing: {set(dtype_map.keys()) - set(df.columns)}\")\n",
    "        print(f\"Column mismatch: Extra: {set(df.columns) - set(dtype_map.keys())}\")\n",
    "        return False, \"Schema structure is incorrect.\"\n",
    "        \n",
    "    # check the data structure of the attributes\n",
    "    for col, expected_dtype in dtype_map.items():\n",
    "        if str(df[col].dtype) != expected_dtype.lower():\n",
    "            return False, f\"Invalid data type for {col}. Expected: {expected_dtype}.\"\n",
    "\n",
    "    # check for any null values and duplicate values\n",
    "    for col in dtype_map:\n",
    "        null_counts = df[col].isna().sum()\n",
    "        \n",
    "        if null_counts > 0:\n",
    "            print(f\"{col} has {null_counts} null values.\")\n",
    "    dup_counts = df.duplicated().sum()\n",
    "    print(f\"DataFrame df has {dup_counts} duplicate rows.\")\n",
    "    \n",
    "    # how to check for numerical outliers\n",
    "    for col in df.select_dtypes(include='number'):\n",
    "        report = check_outliers_zscore(df[col])\n",
    "        if report['count'] > 0:\n",
    "            print(f\"Outliers for {col}: {report['count']} ({report['percentage']:.2f}%)\")\n",
    "        else:\n",
    "            continue\n",
    "    return True, \"DataFrame is valid.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c5a8cf-d2d1-4c45-ba48-967683a16ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cylinders has 482 null values.\n",
      "horsepower has 708 null values.\n",
      "acceleration has 930 null values.\n",
      "num_doors has 502 null values.\n",
      "DataFrame df has 0 duplicate rows.\n",
      "Outliers for engine_displacement: 39 (0.40%)\n",
      "Outliers for num_cylinders: 81 (0.83%)\n",
      "Outliers for horsepower: 19 (0.20%)\n",
      "Outliers for vehicle_weight: 28 (0.29%)\n",
      "Outliers for acceleration: 25 (0.26%)\n",
      "Outliers for num_doors: 5 (0.05%)\n",
      "Outliers for fuel_efficiency_mpg: 27 (0.28%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 'DataFrame is valid.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Preparing the dataset\n",
    "validate_dataframe_comprehensive(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a12407-3a71-4b1d-93f2-e36a08cec007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine_displacement    False\n",
      "num_cylinders          False\n",
      "horsepower             False\n",
      "vehicle_weight         False\n",
      "acceleration           False\n",
      "model_year             False\n",
      "origin                 False\n",
      "fuel_type              False\n",
      "drivetrain             False\n",
      "num_doors              False\n",
      "fuel_efficiency_mpg    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# fill missing values with zeros\n",
    "df1 = df.fillna(0)\n",
    "print(df1.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c1e56-d0ba-4fa3-b862-c3abf1c3b163",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the `fuel_efficiency_mpg` variable. \n",
    "\n",
    "* Train a model with `max_depth=1`.\n",
    "\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "\n",
    "* `'vehicle_weight'`\n",
    "* `'model_year'`\n",
    "* `'origin'`\n",
    "* `'fuel_type'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a76ee107-0aec-4a3a-bbaa-4abf016c5f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle_weight\n"
     ]
    }
   ],
   "source": [
    "### Question 1\n",
    "# Do train/validation/test split with 60%/20%/20% distribution. \n",
    "# Use the `train_test_split` function and set the `random_state` parameter to 1.\n",
    "# Use `DictVectorizer(sparse=True)` to turn the dataframes into matrices.\n",
    "\n",
    "df_train, df_temp = train_test_split(df1, \n",
    "                              random_state=1, \n",
    "                              test_size=0.4)\n",
    "df_val, df_test = train_test_split(df_temp, \n",
    "                                   random_state=1,\n",
    "                                   test_size=0.5)\n",
    "target = \"fuel_efficiency_mpg\"\n",
    "train_y = df_train[target]\n",
    "df_train_X = df_train.drop(columns=[target])\n",
    "test_y = df_test[target]\n",
    "df_test_X = df_test.drop(columns=[target])\n",
    "val_y = df_val[target]\n",
    "df_val_X = df_val.drop(columns=[target])\n",
    "\n",
    "# vectorize into matrix\n",
    "v = DictVectorizer(sparse=True)\n",
    "train_X_matrix = v.fit_transform(df_train_X.to_dict(orient='records'))\n",
    "val_X_matrix = v.transform(df_val_X.to_dict(orient='records'))\n",
    "test_X_matrix = v.transform(df_test_X.to_dict(orient='records'))\n",
    "\n",
    "# train a decision tree regressor to predict the `fuel_efficiency_mpg` variable\n",
    "DT = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "DT.fit(train_X_matrix, train_y)\n",
    "\n",
    "# print feature importance\n",
    "importances = DT.feature_importances_\n",
    "\n",
    "# Get the index of the most important feature\n",
    "idx = np.argmax([importances])\n",
    "\n",
    "# Get the feature name with the highest feature importance\n",
    "feature_names = v.feature_names_\n",
    "print(feature_names[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17439fd1-b303-4862-bfbb-7b1ead6223b9",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2\n",
    "\n",
    "Train a random forest regressor with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1` (optional - to make training faster)\n",
    "\n",
    "$$\n",
    "\\text{MSE=} \\sum^n_{i=1}{(y_i - \\hat{y_i})^2}\n",
    "$$\n",
    "$$\n",
    "\\text{RMSE=} \\sqrt{\\frac{\\text{MSE}}{n}}\n",
    "$$\n",
    "What's the RMSE of this model on the validation data?\n",
    "\n",
    "* 0.045\n",
    "* 0.45\n",
    "* 4.5\n",
    "* 45.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66b6ec39-01ae-44ab-bb97-eb992b287c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R square is 0.9673841548317689\n",
      "RMSE is 0.4602815367032659\n"
     ]
    }
   ],
   "source": [
    "### Question 2\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1,n_jobs=-1)\n",
    "rf.fit(train_X_matrix, train_y)\n",
    "\n",
    "pred_y = rf.predict(val_X_matrix)\n",
    "\n",
    "## compute R^2\n",
    "u = ((val_y - pred_y)** 2).sum()\n",
    "v = ((val_y - val_y.mean()) ** 2).sum()\n",
    "n = len(val_y)\n",
    "R_squared = 1-(u/v)\n",
    "RMSE = np.sqrt(u/n)\n",
    "\n",
    "print(f\"R square is {R_squared}\")\n",
    "print(f\"RMSE is {RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c926b0-cfb0-4217-9056-e96e90753982",
   "metadata": {},
   "source": [
    "\n",
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10.\n",
    "* Set `random_state` to `1`.\n",
    "* Evaluate the model on the validation dataset.\n",
    "\n",
    "\n",
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "Consider 3 decimal places for calculating the answer.\n",
    "\n",
    "- 10\n",
    "- 25\n",
    "- 80\n",
    "- 200\n",
    "\n",
    "If it doesn't stop improving, use the latest iteration number in\n",
    "your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18b4e25c-dd45-4552-a71e-5bfcf630968e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All RMSE results: {10: np.float64(0.4602815367032658), 20: np.float64(0.44615674589110027), 30: np.float64(0.4397780761280069), 40: np.float64(0.4383939265191818), 50: np.float64(0.43717032494674524), 60: np.float64(0.4355914081920472), 70: np.float64(0.43611238591302576), 80: np.float64(0.43605455887808786), 90: np.float64(0.43541008234407647), 100: np.float64(0.4352773655478666), 110: np.float64(0.434896815770466), 120: np.float64(0.43546652508605704), 130: np.float64(0.4349233620666645), 140: np.float64(0.4351068229164201), 150: np.float64(0.4351910645153306), 160: np.float64(0.4352369042756664), 170: np.float64(0.43520773900215154), 180: np.float64(0.4352404093499596), 190: np.float64(0.43539799338117574), 200: np.float64(0.4350031248889441)}\n",
      "####################\n",
      "The best n_estimator is: 110\n",
      "The minimum RMSE achieved is: 0.4349\n"
     ]
    }
   ],
   "source": [
    "### Question 3\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "min_rmse = float('inf')  # Tracks the best (lowest) RMSE found across all iterations.\n",
    "best_n_estimator = 0     # Tracks the n_estimator corresponding to the min_rmse.\n",
    "results = {}             # Stores all results for later inspection (n: rmse)\n",
    "\n",
    "\n",
    "for n in range(10, 201, 10):\n",
    "    # 1. Fit with Random Forest Regressor\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1,warm_start=True)\n",
    "    rf.fit(train_X_matrix, train_y)\n",
    "\n",
    "    pred_y = rf.predict(val_X_matrix)\n",
    "    \n",
    "    # 2. Compute RMSE\n",
    "    u = ((val_y - pred_y)** 2).sum()\n",
    "    current_rmse = np.sqrt(u / len(val_y))\n",
    "\n",
    "    # 3. Store the result\n",
    "    results[n] = current_rmse\n",
    "    \n",
    "    # 4. Compare the current RMSE to the overall \n",
    "    if current_rmse < min_rmse:\n",
    "        min_rmse = current_rmse      # Update the overall minimum RMSE\n",
    "        best_n_estimator = n         # Update the n_estimator that achieved it\n",
    "        \n",
    "print(f\"All RMSE results: {results}\")\n",
    "print(\"#\" * 20)\n",
    "print(f\"The best n_estimator is: {best_n_estimator}\")\n",
    "print(f\"The minimum RMSE achieved is: {min_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ae05c-4e0b-46a5-bec1-96879791dcad",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values,\n",
    "  * try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "  * calculate the mean RMSE \n",
    "* Fix the random seed: `random_state=1`\n",
    "\n",
    "\n",
    "What's the best `max_depth`, using the mean RMSE?\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6b0e9b3-1478-473f-9b5b-602e3f3befe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 10\n"
     ]
    }
   ],
   "source": [
    "### Question 4 to find the best max_depth, using the mean RMSE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_rf = RandomForestRegressor(random_state=1, n_jobs=-1)\n",
    "param_grid = {\n",
    "    'max_depth': [20, 25, 10, 15],\n",
    "    'n_estimators': list(range(10,201,10))\n",
    "}\n",
    "\n",
    "min_mean_rmse = float('inf') # Tracks the overall lowest mean RMSE\n",
    "best_max_depth = 0\n",
    "mean_rmse_results = {}\n",
    "\n",
    "for m in param_grid['max_depth']:\n",
    "    # initialize the model using the current max_depth\n",
    "    rf = RandomForestRegressor(\n",
    "        max_depth=m, \n",
    "        random_state=1, \n",
    "        n_jobs=-1,\n",
    "        warm_start=True \n",
    "    )\n",
    "    # set an array to aggregate the scores\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for n in param_grid['n_estimators']:\n",
    "        rf.set_params(n_estimators=n)\n",
    "        rf.fit(train_X_matrix, train_y)\n",
    "        pred_y = rf.predict(val_X_matrix)\n",
    "        \n",
    "        # Compute RSME\n",
    "        u = ((val_y - pred_y)**2).sum()\n",
    "        RMSE = np.sqrt(u / len(val_y))\n",
    "\n",
    "        # Store the individual RMSE score for this depth\n",
    "        rmse_scores.append(RMSE)\n",
    "        \n",
    "    mean_rmse = np.mean(rmse_scores)\n",
    "    mean_rmse_results[m] = mean_rmse \n",
    "\n",
    "    # Compare the current RMSE to the overall \n",
    "    if mean_rmse < min_mean_rmse:\n",
    "        min_mean_rmse = mean_rmse      \n",
    "        best_max_depth = m        \n",
    "print(f\"Best max_depth: {best_max_depth}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9245e-dd97-4f7c-b107-e0905d1413b0",
   "metadata": {},
   "source": [
    "\n",
    "# Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorithm, it finds the best split. \n",
    "When doing it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the important features for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the\n",
    "[`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_)\n",
    "field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parameters:\n",
    "  * `n_estimators=10`,\n",
    "  * `max_depth=20`,\n",
    "  * `random_state=1`,\n",
    "  * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model\n",
    "\n",
    "\n",
    "What's the most important feature (among these 4)? \n",
    "\n",
    "* `vehicle_weight`\n",
    "*\t`horsepower`\n",
    "* `acceleration`\n",
    "* `engine_displacement`\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0c76791-7ca8-4161-8e5a-f5b3e587c09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acceleration', 'drivetrain=All-wheel drive', 'drivetrain=Front-wheel drive', 'engine_displacement', 'fuel_type=Diesel', 'fuel_type=Gasoline', 'horsepower', 'model_year', 'num_cylinders', 'num_doors', 'origin=Asia', 'origin=Europe', 'origin=USA', 'vehicle_weight']\n"
     ]
    }
   ],
   "source": [
    "v = DictVectorizer(sparse=True)\n",
    "v.fit_transform(df_train_X.to_dict(orient='records'))\n",
    "print(v.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b51bd58-bddc-46d2-83ea-e8e388a469d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle_weight\n"
     ]
    }
   ],
   "source": [
    "## Question 5\n",
    "rf = RandomForestRegressor(n_estimators=10, max_depth=20,random_state=1,n_jobs=-1)\n",
    "rf.fit(train_X_matrix,train_y)\n",
    "\n",
    "# record feature importance\n",
    "importances = rf.feature_importances_\n",
    "idx = np.argmax([importances])\n",
    "\n",
    "# find the most important feature\n",
    "feature_names = v.feature_names_\n",
    "print(feature_names[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296273ea-01f7-4378-ae5a-d6dfb6d6da5c",
   "metadata": {},
   "source": [
    "\n",
    "## Question 6\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter:\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```\n",
    "\n",
    "Now change `eta` from `0.3` to `0.1`.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* Both give equal value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d4139b8-f1d5-4fb7-8f24-e998fba1c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7fa1090-6023-48b1-8cff-d79f13ced2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.42799904532270117\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 1. Set parameters dictionary\n",
    "xgb_params = {\n",
    "    \"eta\": 0.1,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"nthread\": 4,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# 2. Initialize the model \n",
    "# Pass the parameters and set the number of estimators (trees)\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100, # Corresponds to num_boost_round\n",
    "    objective='reg:squarederror', # Explicitly set for standard regression\n",
    "    **xgb_params # Unpack the remaining parameters\n",
    ")\n",
    "\n",
    "# 3. Fit the model \n",
    "# Use your original data matrices (assuming val_X and val_y are NumPy arrays/Pandas Series)\n",
    "model.fit(\n",
    "    train_X_matrix, train_y,\n",
    "    # Use the validation set for early stopping if desired\n",
    "    eval_set=[(val_X_matrix, val_y)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 4. Make predictions \n",
    "pred_y = model.predict(val_X_matrix)\n",
    "\n",
    "# 5. Evaluate performance RMSE\n",
    "u = ((val_y - pred_y)**2).sum()\n",
    "RMSE = np.sqrt(u / len(val_y))\n",
    "\n",
    "print(f\"RMSE is {RMSE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1c42ad6-58d1-4964-8ec8-bc6dc568924c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.4595951501538645\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 1. Set parameters dictionary to eta = 0.3\n",
    "xgb_params = {\n",
    "    \"eta\": 0.3,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"nthread\": 4,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# 2. Initialize the model \n",
    "# Pass the parameters and set the number of estimators (trees)\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100, # Corresponds to num_boost_round\n",
    "    objective='reg:squarederror', # Explicitly set for standard regression\n",
    "    **xgb_params # Unpack the remaining parameters\n",
    ")\n",
    "\n",
    "# 3. Fit the model \n",
    "# Use your original data matrices (assuming val_X and val_y are NumPy arrays/Pandas Series)\n",
    "model.fit(\n",
    "    train_X_matrix, train_y,\n",
    "    # Use the validation set for early stopping if desired\n",
    "    eval_set=[(val_X_matrix, val_y)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 4. Make predictions \n",
    "pred_y = model.predict(val_X_matrix)\n",
    "\n",
    "# 5. Evaluate performance RMSE\n",
    "u = ((val_y - pred_y)**2).sum()\n",
    "RMSE = np.sqrt(u / len(val_y))\n",
    "\n",
    "print(f\"RMSE is {RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d9efca-e6ce-489a-968b-e5821e110405",
   "metadata": {},
   "source": [
    "$\\text{eta} = 0.1$: This is a lower learning rate. The model takes smaller, more cautious steps. This typically requires a larger number of boosting rounds (num_boost_round or n_estimators) but often results in a more robust model that generalizes better to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292d17d-d8a2-45a4-aff2-e0c461b6aeb2",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw06\n",
    "* If your answer doesn't match options exactly, select the closest one. If the answer is exactly in between two options, select the higher value.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
